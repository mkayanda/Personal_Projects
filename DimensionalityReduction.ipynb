{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are unsupervised learning algorithms where the class labels are unknown. We draw inferences from datasets consisting of input data where the answer is unknown. \n",
    "\n",
    "Dimensionality reduction compressed the data by finding a smaller, different set of variables that capture what matters most in the orignial features, while minimizing the loss of information. It helps mitigate problems associated with high dimensionality and permits the visualization of salient aspects of higher-dimensional data that is otherwise difficult to explore. \n",
    "\n",
    "Three most frequently used techniques for dimensionality reduction:\n",
    "\n",
    "    1. principal component analysis(PCA)\n",
    "    2. kernel principal component analysis (KPCA)\n",
    "    3. t-distributed stochastic neighbor embedding (t-SNE)\n",
    "    \n",
    "    \n",
    "**PCA** aims to reduce the dimensionality of a dataset with a large number of variables while retaining as much variance in the data as possible. It dinds a set of new variables that through a linear combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
